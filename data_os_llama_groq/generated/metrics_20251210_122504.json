{
  "start_time": "2025-12-10T12:25:04.780120",
  "end_time": "2025-12-10T12:32:16.408215",
  "target_samples": 100,
  "total_generated": 100,
  "total_accepted": 100,
  "total_rejected": 0,
  "total_regenerations": 0,
  "model_metrics": {
    "groq:llama-3.3-70b-versatile": {
      "model_name": "groq:llama-3.3-70b-versatile",
      "samples_generated": 100,
      "samples_accepted": 100,
      "total_time": 149.10403180122375,
      "total_cost": 0.006885399999999996,
      "avg_quality_score": 0.6436902685621108,
      "avg_llm_judge_score": 0.0,
      "quality_scores": [
        1.0,
        0.9748518945683519,
        0.9543124343890295,
        0.943685893139544,
        0.9070648041313871,
        0.8867175433887994,
        0.8423597924118877,
        0.8409345134154758,
        0.8244501739019876,
        0.8092960184943552,
        0.8124268799738504,
        0.7908525541129052,
        0.7615611363431745,
        0.7486281312158516,
        0.7418073964416223,
        0.7485382719266764,
        0.7395585056268654,
        0.7346177414725445,
        0.7228999895174526,
        0.712592690509205,
        0.7157775309937005,
        0.7149935948351744,
        0.7026460199585228,
        0.6957472370355684,
        0.6909539754037777,
        0.68223090218241,
        0.6822762093525735,
        0.6748025003948879,
        0.6688276656491472,
        0.6621043863770446,
        0.6648020911759353,
        0.6601989059500424,
        0.6570286704192414,
        0.6555776807427298,
        0.6494754431433734,
        0.6478595046998886,
        0.6449022411814915,
        0.6424494524532582,
        0.6393281231912848,
        0.634102317478587,
        0.6314037103605716,
        0.6306324742039531,
        0.6336457969633675,
        0.6299242656833093,
        0.6291226509463113,
        0.6277872461120059,
        0.6237281947218603,
        0.6218086809271524,
        0.6179371660680897,
        0.6142928593459163,
        0.6108892842681615,
        0.6060434001319688,
        0.6025705727144013,
        0.6025472755001773,
        0.601430732700331,
        0.5969342055823005,
        0.5951231479494574,
        0.5937302031918736,
        0.5898317967952043,
        0.5879001265159254,
        0.5873914873908943,
        0.5839604289851075,
        0.5813967582398781,
        0.5810164655488115,
        0.5793597786666153,
        0.5776852963995748,
        0.5752513002238802,
        0.5765626142637403,
        0.5740412287762497,
        0.5714404213341217,
        0.5691095586763455,
        0.5696896149029198,
        0.567683775554112,
        0.564335819336939,
        0.5635963417202026,
        0.562980848117382,
        0.5608267266052245,
        0.5588144593610422,
        0.5563325506474878,
        0.5551989947153699,
        0.552627817267465,
        0.5511994426454145,
        0.5498422961636795,
        0.5478477789058898,
        0.5466548728617335,
        0.545861757069341,
        0.5469913836769555,
        0.5443806377993887,
        0.5439761185542529,
        0.5412214123747421,
        0.5412310795591104,
        0.541219881601998,
        0.5384801952564926,
        0.5376187513798054,
        0.5356092509735187,
        0.5347305010558794,
        0.532466736141653,
        0.5313383051950757,
        0.5299399469589537,
        0.5285896130218766
      ],
      "llm_judge_scores": []
    }
  },
  "llm_judge_evaluations": 0,
  "llm_judge_pass_rate": 0.0,
  "judge_agreement_rate": 0.0,
  "avg_diversity_score": 0.6436902685621108,
  "avg_self_bleu": 0.6436902685621108,
  "avg_sentiment_alignment": 0.6302622883021831,
  "avg_realism_score": 0.0,
  "rejection_reasons": {},
  "total_time": 431.628095,
  "success_rate": 1.0,
  "total_cost": 0.006885399999999996
}