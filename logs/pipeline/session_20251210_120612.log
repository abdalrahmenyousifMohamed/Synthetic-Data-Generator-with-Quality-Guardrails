2025-12-10 12:06:16,110 - SyntheticReviewGen - INFO - Loading sentiment model...
2025-12-10 12:06:17,060 - SyntheticReviewGen - INFO - ✓ 5-star sentiment model loaded
2025-12-10 12:06:17,066 - SyntheticReviewGen - INFO - Building workflow WITHOUT LLM Judge (statistical checks only)
2025-12-10 12:06:17,083 - SyntheticReviewGen - INFO - Starting dataset generation: 300 samples
2025-12-10 12:06:17,085 - SyntheticReviewGen - INFO - Generating review rev_0001 (attempt 1)
2025-12-10 12:06:18,773 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:06:19,344 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.58, alignment=0.58, threshold=0.10, mismatch=False
2025-12-10 12:06:19,345 - SyntheticReviewGen - INFO - ✅ Review rev_0001 accepted after 1 attempt(s)!
2025-12-10 12:06:19,346 - SyntheticReviewGen - INFO - Progress: 1/300 reviews generated
2025-12-10 12:06:19,346 - SyntheticReviewGen - INFO - Generating review rev_0002 (attempt 1)
2025-12-10 12:06:20,993 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:06:21,067 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=4, diff=1, confidence=0.67, alignment=0.57, threshold=0.10, mismatch=False
2025-12-10 12:06:21,070 - SyntheticReviewGen - INFO - ✅ Review rev_0002 accepted after 1 attempt(s)!
2025-12-10 12:06:21,070 - SyntheticReviewGen - INFO - Progress: 2/300 reviews generated
2025-12-10 12:06:21,071 - SyntheticReviewGen - INFO - Generating review rev_0003 (attempt 1)
2025-12-10 12:06:22,258 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:06:22,336 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=4, diff=1, confidence=0.57, alignment=0.48, threshold=0.10, mismatch=False
2025-12-10 12:06:22,340 - SyntheticReviewGen - INFO - ✅ Review rev_0003 accepted after 1 attempt(s)!
2025-12-10 12:06:22,341 - SyntheticReviewGen - INFO - Progress: 3/300 reviews generated
2025-12-10 12:06:22,341 - SyntheticReviewGen - INFO - Generating review rev_0004 (attempt 1)
2025-12-10 12:06:23,481 - SyntheticReviewGen - INFO - Sentiment check: rating=5, attempt=1, base_threshold=0.25, adjusted=0.15
2025-12-10 12:06:23,553 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=5, diff=0, confidence=0.72, alignment=0.72, threshold=0.15, mismatch=False
2025-12-10 12:06:23,559 - SyntheticReviewGen - INFO - ✅ Review rev_0004 accepted after 1 attempt(s)!
2025-12-10 12:06:23,560 - SyntheticReviewGen - INFO - Progress: 4/300 reviews generated
2025-12-10 12:06:23,560 - SyntheticReviewGen - INFO - Generating review rev_0005 (attempt 1)
2025-12-10 12:06:24,615 - SyntheticReviewGen - INFO - Sentiment check: rating=2, attempt=1, base_threshold=0.15, adjusted=0.05
2025-12-10 12:06:24,684 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=2, expected=2, diff=0, confidence=0.56, alignment=0.56, threshold=0.05, mismatch=False
2025-12-10 12:06:24,692 - SyntheticReviewGen - INFO - ✅ Review rev_0005 accepted after 1 attempt(s)!
2025-12-10 12:06:24,692 - SyntheticReviewGen - INFO - Progress: 5/300 reviews generated
2025-12-10 12:06:24,693 - SyntheticReviewGen - INFO - Generating review rev_0006 (attempt 1)
2025-12-10 12:06:26,043 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:06:26,103 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.65, alignment=0.65, threshold=0.10, mismatch=False
2025-12-10 12:06:26,115 - SyntheticReviewGen - INFO - ✅ Review rev_0006 accepted after 1 attempt(s)!
2025-12-10 12:06:26,116 - SyntheticReviewGen - INFO - Progress: 6/300 reviews generated
2025-12-10 12:06:26,116 - SyntheticReviewGen - INFO - Generating review rev_0007 (attempt 1)
2025-12-10 12:06:27,721 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:06:27,786 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.56, alignment=0.56, threshold=0.10, mismatch=False
2025-12-10 12:06:27,804 - SyntheticReviewGen - INFO - ✅ Review rev_0007 accepted after 1 attempt(s)!
2025-12-10 12:06:27,804 - SyntheticReviewGen - INFO - Progress: 7/300 reviews generated
2025-12-10 12:06:27,805 - SyntheticReviewGen - INFO - Generating review rev_0008 (attempt 1)
2025-12-10 12:06:29,938 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:06:30,012 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=4, diff=1, confidence=0.46, alignment=0.39, threshold=0.10, mismatch=False
2025-12-10 12:06:30,035 - SyntheticReviewGen - INFO - ✅ Review rev_0008 accepted after 1 attempt(s)!
2025-12-10 12:06:30,035 - SyntheticReviewGen - INFO - Progress: 8/300 reviews generated
2025-12-10 12:06:30,036 - SyntheticReviewGen - INFO - Generating review rev_0009 (attempt 1)
2025-12-10 12:06:31,677 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:06:31,744 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.60, alignment=0.60, threshold=0.10, mismatch=False
2025-12-10 12:06:31,774 - SyntheticReviewGen - INFO - ✅ Review rev_0009 accepted after 1 attempt(s)!
2025-12-10 12:06:31,775 - SyntheticReviewGen - INFO - Progress: 9/300 reviews generated
2025-12-10 12:06:31,775 - SyntheticReviewGen - INFO - Generating review rev_0010 (attempt 1)
2025-12-10 12:06:32,905 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:06:32,985 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=3, diff=1, confidence=0.56, alignment=0.48, threshold=0.05, mismatch=False
2025-12-10 12:06:33,022 - SyntheticReviewGen - INFO - ✅ Review rev_0010 accepted after 1 attempt(s)!
2025-12-10 12:06:33,022 - SyntheticReviewGen - INFO - Progress: 10/300 reviews generated
2025-12-10 12:06:33,022 - SyntheticReviewGen - INFO - Generating review rev_0011 (attempt 1)
2025-12-10 12:06:34,647 - SyntheticReviewGen - INFO - Sentiment check: rating=5, attempt=1, base_threshold=0.25, adjusted=0.15
2025-12-10 12:06:34,716 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=5, diff=0, confidence=0.87, alignment=0.87, threshold=0.15, mismatch=False
2025-12-10 12:06:34,760 - SyntheticReviewGen - INFO - ✅ Review rev_0011 accepted after 1 attempt(s)!
2025-12-10 12:06:34,761 - SyntheticReviewGen - INFO - Progress: 11/300 reviews generated
2025-12-10 12:06:34,761 - SyntheticReviewGen - INFO - Generating review rev_0012 (attempt 1)
2025-12-10 12:06:35,768 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:06:35,905 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=3, expected=3, diff=0, confidence=0.64, alignment=0.64, threshold=0.05, mismatch=False
2025-12-10 12:06:35,955 - SyntheticReviewGen - INFO - ✅ Review rev_0012 accepted after 1 attempt(s)!
2025-12-10 12:06:35,955 - SyntheticReviewGen - INFO - Progress: 12/300 reviews generated
2025-12-10 12:06:35,956 - SyntheticReviewGen - INFO - Generating review rev_0013 (attempt 1)
2025-12-10 12:06:36,903 - SyntheticReviewGen - INFO - Sentiment check: rating=5, attempt=1, base_threshold=0.25, adjusted=0.15
2025-12-10 12:06:36,965 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=5, diff=0, confidence=0.63, alignment=0.63, threshold=0.15, mismatch=False
2025-12-10 12:06:37,021 - SyntheticReviewGen - INFO - ✅ Review rev_0013 accepted after 1 attempt(s)!
2025-12-10 12:06:37,021 - SyntheticReviewGen - INFO - Progress: 13/300 reviews generated
2025-12-10 12:06:37,022 - SyntheticReviewGen - INFO - Generating review rev_0014 (attempt 1)
2025-12-10 12:06:38,156 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:06:38,222 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.72, alignment=0.72, threshold=0.10, mismatch=False
2025-12-10 12:06:38,286 - SyntheticReviewGen - INFO - ✅ Review rev_0014 accepted after 1 attempt(s)!
2025-12-10 12:06:38,286 - SyntheticReviewGen - INFO - Progress: 14/300 reviews generated
2025-12-10 12:06:38,286 - SyntheticReviewGen - INFO - Generating review rev_0015 (attempt 1)
2025-12-10 12:06:39,365 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:06:39,445 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.82, alignment=0.82, threshold=0.10, mismatch=False
2025-12-10 12:06:39,515 - SyntheticReviewGen - INFO - ✅ Review rev_0015 accepted after 1 attempt(s)!
2025-12-10 12:06:39,516 - SyntheticReviewGen - INFO - Progress: 15/300 reviews generated
2025-12-10 12:06:39,516 - SyntheticReviewGen - INFO - Generating review rev_0016 (attempt 1)
2025-12-10 12:06:40,755 - SyntheticReviewGen - INFO - Sentiment check: rating=5, attempt=1, base_threshold=0.25, adjusted=0.15
2025-12-10 12:06:40,818 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=5, diff=0, confidence=0.70, alignment=0.70, threshold=0.15, mismatch=False
2025-12-10 12:06:40,897 - SyntheticReviewGen - INFO - ✅ Review rev_0016 accepted after 1 attempt(s)!
2025-12-10 12:06:40,897 - SyntheticReviewGen - INFO - Progress: 16/300 reviews generated
2025-12-10 12:06:40,897 - SyntheticReviewGen - INFO - Generating review rev_0017 (attempt 1)
2025-12-10 12:06:42,630 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:06:42,696 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=4, diff=1, confidence=0.75, alignment=0.63, threshold=0.10, mismatch=False
2025-12-10 12:06:42,787 - SyntheticReviewGen - INFO - ✅ Review rev_0017 accepted after 1 attempt(s)!
2025-12-10 12:06:42,787 - SyntheticReviewGen - INFO - Progress: 17/300 reviews generated
2025-12-10 12:06:42,788 - SyntheticReviewGen - INFO - Generating review rev_0018 (attempt 1)
2025-12-10 12:06:44,274 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:06:44,354 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=3, diff=1, confidence=0.53, alignment=0.45, threshold=0.05, mismatch=False
2025-12-10 12:06:44,456 - SyntheticReviewGen - INFO - ✅ Review rev_0018 accepted after 1 attempt(s)!
2025-12-10 12:06:44,456 - SyntheticReviewGen - INFO - Progress: 18/300 reviews generated
2025-12-10 12:06:44,457 - SyntheticReviewGen - INFO - Generating review rev_0019 (attempt 1)
2025-12-10 12:06:45,957 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:06:46,016 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.61, alignment=0.61, threshold=0.10, mismatch=False
2025-12-10 12:06:46,132 - SyntheticReviewGen - INFO - ✅ Review rev_0019 accepted after 1 attempt(s)!
2025-12-10 12:06:46,133 - SyntheticReviewGen - INFO - Progress: 19/300 reviews generated
2025-12-10 12:06:46,133 - SyntheticReviewGen - INFO - Generating review rev_0020 (attempt 1)
2025-12-10 12:06:48,161 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:06:48,234 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=3, diff=1, confidence=0.58, alignment=0.50, threshold=0.05, mismatch=False
2025-12-10 12:06:48,366 - SyntheticReviewGen - INFO - ✅ Review rev_0020 accepted after 1 attempt(s)!
2025-12-10 12:06:48,366 - SyntheticReviewGen - INFO - Progress: 20/300 reviews generated
2025-12-10 12:06:48,366 - SyntheticReviewGen - INFO - Generating review rev_0021 (attempt 1)
2025-12-10 12:06:49,905 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:06:49,987 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.95, alignment=0.95, threshold=0.10, mismatch=False
2025-12-10 12:06:50,131 - SyntheticReviewGen - INFO - ✅ Review rev_0021 accepted after 1 attempt(s)!
2025-12-10 12:06:50,132 - SyntheticReviewGen - INFO - Progress: 21/300 reviews generated
2025-12-10 12:06:50,132 - SyntheticReviewGen - INFO - Generating review rev_0022 (attempt 1)
2025-12-10 12:06:51,750 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:06:51,818 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.74, alignment=0.74, threshold=0.10, mismatch=False
2025-12-10 12:06:51,977 - SyntheticReviewGen - INFO - ✅ Review rev_0022 accepted after 1 attempt(s)!
2025-12-10 12:06:51,977 - SyntheticReviewGen - INFO - Progress: 22/300 reviews generated
2025-12-10 12:06:51,978 - SyntheticReviewGen - INFO - Generating review rev_0023 (attempt 1)
2025-12-10 12:06:53,736 - SyntheticReviewGen - INFO - Sentiment check: rating=5, attempt=1, base_threshold=0.25, adjusted=0.15
2025-12-10 12:06:53,812 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=5, diff=0, confidence=0.82, alignment=0.82, threshold=0.15, mismatch=False
2025-12-10 12:06:53,990 - SyntheticReviewGen - INFO - ✅ Review rev_0023 accepted after 1 attempt(s)!
2025-12-10 12:06:53,990 - SyntheticReviewGen - INFO - Progress: 23/300 reviews generated
2025-12-10 12:06:53,991 - SyntheticReviewGen - INFO - Generating review rev_0024 (attempt 1)
2025-12-10 12:06:55,127 - SyntheticReviewGen - INFO - Sentiment check: rating=5, attempt=1, base_threshold=0.25, adjusted=0.15
2025-12-10 12:06:55,199 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=5, diff=0, confidence=0.66, alignment=0.66, threshold=0.15, mismatch=False
2025-12-10 12:06:55,390 - SyntheticReviewGen - INFO - ✅ Review rev_0024 accepted after 1 attempt(s)!
2025-12-10 12:06:55,390 - SyntheticReviewGen - INFO - Progress: 24/300 reviews generated
2025-12-10 12:06:55,391 - SyntheticReviewGen - INFO - Generating review rev_0025 (attempt 1)
2025-12-10 12:06:56,248 - SyntheticReviewGen - INFO - Sentiment check: rating=5, attempt=1, base_threshold=0.25, adjusted=0.15
2025-12-10 12:06:56,303 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=5, diff=1, confidence=0.51, alignment=0.43, threshold=0.15, mismatch=False
2025-12-10 12:06:56,507 - SyntheticReviewGen - INFO - ✅ Review rev_0025 accepted after 1 attempt(s)!
2025-12-10 12:06:56,507 - SyntheticReviewGen - INFO - Progress: 25/300 reviews generated
2025-12-10 12:06:56,508 - SyntheticReviewGen - INFO - Generating review rev_0026 (attempt 1)
2025-12-10 12:06:58,095 - SyntheticReviewGen - INFO - Sentiment check: rating=1, attempt=1, base_threshold=0.15, adjusted=0.05
2025-12-10 12:06:58,164 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=2, expected=1, diff=1, confidence=0.73, alignment=0.62, threshold=0.05, mismatch=False
2025-12-10 12:06:58,387 - SyntheticReviewGen - INFO - ✅ Review rev_0026 accepted after 1 attempt(s)!
2025-12-10 12:06:58,388 - SyntheticReviewGen - INFO - Progress: 26/300 reviews generated
2025-12-10 12:06:58,388 - SyntheticReviewGen - INFO - Generating review rev_0027 (attempt 1)
2025-12-10 12:06:59,285 - SyntheticReviewGen - INFO - Sentiment check: rating=2, attempt=1, base_threshold=0.15, adjusted=0.05
2025-12-10 12:06:59,358 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=2, expected=2, diff=0, confidence=0.66, alignment=0.66, threshold=0.05, mismatch=False
2025-12-10 12:06:59,603 - SyntheticReviewGen - INFO - ✅ Review rev_0027 accepted after 1 attempt(s)!
2025-12-10 12:06:59,603 - SyntheticReviewGen - INFO - Progress: 27/300 reviews generated
2025-12-10 12:06:59,604 - SyntheticReviewGen - INFO - Generating review rev_0028 (attempt 1)
2025-12-10 12:07:01,192 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:01,255 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=3, diff=1, confidence=0.52, alignment=0.44, threshold=0.05, mismatch=False
2025-12-10 12:07:01,512 - SyntheticReviewGen - INFO - ✅ Review rev_0028 accepted after 1 attempt(s)!
2025-12-10 12:07:01,513 - SyntheticReviewGen - INFO - Progress: 28/300 reviews generated
2025-12-10 12:07:01,513 - SyntheticReviewGen - INFO - Generating review rev_0029 (attempt 1)
2025-12-10 12:07:03,254 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:07:03,324 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.59, alignment=0.59, threshold=0.10, mismatch=False
2025-12-10 12:07:03,606 - SyntheticReviewGen - INFO - ✅ Review rev_0029 accepted after 1 attempt(s)!
2025-12-10 12:07:03,606 - SyntheticReviewGen - INFO - Progress: 29/300 reviews generated
2025-12-10 12:07:03,606 - SyntheticReviewGen - INFO - Generating review rev_0030 (attempt 1)
2025-12-10 12:07:05,166 - SyntheticReviewGen - INFO - Sentiment check: rating=5, attempt=1, base_threshold=0.25, adjusted=0.15
2025-12-10 12:07:05,241 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=5, diff=0, confidence=0.71, alignment=0.71, threshold=0.15, mismatch=False
2025-12-10 12:07:05,549 - SyntheticReviewGen - INFO - ✅ Review rev_0030 accepted after 1 attempt(s)!
2025-12-10 12:07:05,549 - SyntheticReviewGen - INFO - Progress: 30/300 reviews generated
2025-12-10 12:07:05,550 - SyntheticReviewGen - INFO - Generating review rev_0031 (attempt 1)
2025-12-10 12:07:06,495 - SyntheticReviewGen - INFO - Sentiment check: rating=2, attempt=1, base_threshold=0.15, adjusted=0.05
2025-12-10 12:07:06,554 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=2, expected=2, diff=0, confidence=0.68, alignment=0.68, threshold=0.05, mismatch=False
2025-12-10 12:07:06,870 - SyntheticReviewGen - INFO - ✅ Review rev_0031 accepted after 1 attempt(s)!
2025-12-10 12:07:06,870 - SyntheticReviewGen - INFO - Progress: 31/300 reviews generated
2025-12-10 12:07:06,871 - SyntheticReviewGen - INFO - Generating review rev_0032 (attempt 1)
2025-12-10 12:07:08,344 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:07:08,423 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=4, diff=1, confidence=0.54, alignment=0.46, threshold=0.10, mismatch=False
2025-12-10 12:07:08,761 - SyntheticReviewGen - INFO - ✅ Review rev_0032 accepted after 1 attempt(s)!
2025-12-10 12:07:08,761 - SyntheticReviewGen - INFO - Progress: 32/300 reviews generated
2025-12-10 12:07:08,762 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:08,970 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:09,031 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=3, diff=1, confidence=0.28, alignment=0.24, threshold=0.05, mismatch=False
2025-12-10 12:07:09,379 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12)
2025-12-10 12:07:09,380 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:11,406 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:11,469 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=3, diff=1, confidence=0.50, alignment=0.42, threshold=0.05, mismatch=False
2025-12-10 12:07:11,894 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12)
2025-12-10 12:07:11,895 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:12,107 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:12,174 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=3, diff=1, confidence=0.50, alignment=0.42, threshold=0.05, mismatch=False
2025-12-10 12:07:12,538 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:12,539 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:12,752 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:12,816 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=3, diff=1, confidence=0.50, alignment=0.42, threshold=0.05, mismatch=False
2025-12-10 12:07:13,180 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:13,181 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:14,790 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:14,870 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=3, diff=1, confidence=0.65, alignment=0.55, threshold=0.05, mismatch=False
2025-12-10 12:07:15,231 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:15,232 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:15,477 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:15,547 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=3, diff=1, confidence=0.65, alignment=0.55, threshold=0.05, mismatch=False
2025-12-10 12:07:15,907 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:15,907 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:16,122 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:16,186 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=3, diff=1, confidence=0.65, alignment=0.55, threshold=0.05, mismatch=False
2025-12-10 12:07:16,546 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:16,547 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:17,760 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:17,829 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=3, expected=3, diff=0, confidence=0.45, alignment=0.45, threshold=0.05, mismatch=False
2025-12-10 12:07:18,191 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:18,191 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:18,397 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:18,462 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=3, expected=3, diff=0, confidence=0.45, alignment=0.45, threshold=0.05, mismatch=False
2025-12-10 12:07:18,819 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:18,820 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:19,028 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:19,091 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=3, expected=3, diff=0, confidence=0.45, alignment=0.45, threshold=0.05, mismatch=False
2025-12-10 12:07:19,449 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:19,451 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:19,660 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:19,726 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=3, expected=3, diff=0, confidence=0.45, alignment=0.45, threshold=0.05, mismatch=False
2025-12-10 12:07:20,082 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:20,083 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:21,122 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:21,254 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=3, diff=1, confidence=0.49, alignment=0.42, threshold=0.05, mismatch=False
2025-12-10 12:07:21,610 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:21,610 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:21,821 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:21,887 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=3, diff=1, confidence=0.49, alignment=0.42, threshold=0.05, mismatch=False
2025-12-10 12:07:22,241 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11739, Requested 403. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:22,242 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:22,444 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:22,508 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=3, diff=1, confidence=0.49, alignment=0.42, threshold=0.05, mismatch=False
2025-12-10 12:07:22,861 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11739, Requested 403. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11614, Requested 406. Please try again in 100ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:22,863 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:23,796 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:23,877 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=3, expected=3, diff=0, confidence=0.59, alignment=0.59, threshold=0.05, mismatch=False
2025-12-10 12:07:24,233 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11739, Requested 403. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11614, Requested 406. Please try again in 100ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:24,234 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:24,439 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:24,506 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=3, expected=3, diff=0, confidence=0.59, alignment=0.59, threshold=0.05, mismatch=False
2025-12-10 12:07:24,857 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11739, Requested 403. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11614, Requested 406. Please try again in 100ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11797, Requested 405. Please try again in 1.01s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:24,858 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:25,071 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:25,143 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=3, expected=3, diff=0, confidence=0.59, alignment=0.59, threshold=0.05, mismatch=False
2025-12-10 12:07:25,494 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11739, Requested 403. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11614, Requested 406. Please try again in 100ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11797, Requested 405. Please try again in 1.01s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11670, Requested 406. Please try again in 380ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:25,494 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:26,525 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:26,592 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=3, expected=3, diff=0, confidence=0.63, alignment=0.63, threshold=0.05, mismatch=False
2025-12-10 12:07:26,945 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11739, Requested 403. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11614, Requested 406. Please try again in 100ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11797, Requested 405. Please try again in 1.01s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11670, Requested 406. Please try again in 380ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:26,946 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:27,153 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:27,220 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=3, expected=3, diff=0, confidence=0.63, alignment=0.63, threshold=0.05, mismatch=False
2025-12-10 12:07:27,573 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11739, Requested 403. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11614, Requested 406. Please try again in 100ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11797, Requested 405. Please try again in 1.01s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11670, Requested 406. Please try again in 380ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11855, Requested 402. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:27,574 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:27,792 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:27,856 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=3, expected=3, diff=0, confidence=0.63, alignment=0.63, threshold=0.05, mismatch=False
2025-12-10 12:07:28,208 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11739, Requested 403. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11614, Requested 406. Please try again in 100ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11797, Requested 405. Please try again in 1.01s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11670, Requested 406. Please try again in 380ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11855, Requested 402. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11728, Requested 408. Please try again in 680ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:28,210 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:28,421 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:28,487 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=3, expected=3, diff=0, confidence=0.63, alignment=0.63, threshold=0.05, mismatch=False
2025-12-10 12:07:28,840 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11739, Requested 403. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11614, Requested 406. Please try again in 100ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11797, Requested 405. Please try again in 1.01s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11670, Requested 406. Please try again in 380ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11855, Requested 402. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11728, Requested 408. Please try again in 680ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11601, Requested 408. Please try again in 45ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:28,841 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:29,902 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:29,961 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=3, expected=3, diff=0, confidence=0.65, alignment=0.65, threshold=0.05, mismatch=False
2025-12-10 12:07:30,319 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11739, Requested 403. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11614, Requested 406. Please try again in 100ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11797, Requested 405. Please try again in 1.01s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11670, Requested 406. Please try again in 380ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11855, Requested 402. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11728, Requested 408. Please try again in 680ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11601, Requested 408. Please try again in 45ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:30,321 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:30,535 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:30,596 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=3, expected=3, diff=0, confidence=0.65, alignment=0.65, threshold=0.05, mismatch=False
2025-12-10 12:07:30,962 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11739, Requested 403. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11614, Requested 406. Please try again in 100ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11797, Requested 405. Please try again in 1.01s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11670, Requested 406. Please try again in 380ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11855, Requested 402. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11728, Requested 408. Please try again in 680ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11601, Requested 408. Please try again in 45ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11798, Requested 405. Please try again in 1.014999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:30,963 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:31,166 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:31,223 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=3, expected=3, diff=0, confidence=0.65, alignment=0.65, threshold=0.05, mismatch=False
2025-12-10 12:07:31,584 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11739, Requested 403. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11614, Requested 406. Please try again in 100ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11797, Requested 405. Please try again in 1.01s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11670, Requested 406. Please try again in 380ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11855, Requested 402. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11728, Requested 408. Please try again in 680ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11601, Requested 408. Please try again in 45ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11798, Requested 405. Please try again in 1.014999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11671, Requested 403. Please try again in 370ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:31,585 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:33,217 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:33,284 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=3, diff=1, confidence=0.60, alignment=0.51, threshold=0.05, mismatch=False
2025-12-10 12:07:33,707 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11739, Requested 403. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11614, Requested 406. Please try again in 100ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11797, Requested 405. Please try again in 1.01s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11670, Requested 406. Please try again in 380ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11855, Requested 402. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11728, Requested 408. Please try again in 680ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11601, Requested 408. Please try again in 45ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11798, Requested 405. Please try again in 1.014999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11671, Requested 403. Please try again in 370ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:33,708 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:33,914 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:33,976 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=3, diff=1, confidence=0.60, alignment=0.51, threshold=0.05, mismatch=False
2025-12-10 12:07:34,341 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11739, Requested 403. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11614, Requested 406. Please try again in 100ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11797, Requested 405. Please try again in 1.01s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11670, Requested 406. Please try again in 380ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11855, Requested 402. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11728, Requested 408. Please try again in 680ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11601, Requested 408. Please try again in 45ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11798, Requested 405. Please try again in 1.014999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11671, Requested 403. Please try again in 370ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11851, Requested 404. Please try again in 1.275s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:34,342 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:34,565 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:34,638 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=3, diff=1, confidence=0.60, alignment=0.51, threshold=0.05, mismatch=False
2025-12-10 12:07:35,017 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11739, Requested 403. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11614, Requested 406. Please try again in 100ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11797, Requested 405. Please try again in 1.01s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11670, Requested 406. Please try again in 380ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11855, Requested 402. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11728, Requested 408. Please try again in 680ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11601, Requested 408. Please try again in 45ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11798, Requested 405. Please try again in 1.014999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11671, Requested 403. Please try again in 370ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11851, Requested 404. Please try again in 1.275s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11722, Requested 420. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:35,018 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:35,992 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:36,056 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=3, expected=3, diff=0, confidence=0.46, alignment=0.46, threshold=0.05, mismatch=False
2025-12-10 12:07:36,428 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11739, Requested 403. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11614, Requested 406. Please try again in 100ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11797, Requested 405. Please try again in 1.01s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11670, Requested 406. Please try again in 380ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11855, Requested 402. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11728, Requested 408. Please try again in 680ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11601, Requested 408. Please try again in 45ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11798, Requested 405. Please try again in 1.014999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11671, Requested 403. Please try again in 370ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11851, Requested 404. Please try again in 1.275s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11722, Requested 420. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:36,430 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:36,640 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:36,705 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=3, expected=3, diff=0, confidence=0.46, alignment=0.46, threshold=0.05, mismatch=False
2025-12-10 12:07:37,066 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11739, Requested 403. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11614, Requested 406. Please try again in 100ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11797, Requested 405. Please try again in 1.01s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11670, Requested 406. Please try again in 380ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11855, Requested 402. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11728, Requested 408. Please try again in 680ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11601, Requested 408. Please try again in 45ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11798, Requested 405. Please try again in 1.014999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11671, Requested 403. Please try again in 370ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11851, Requested 404. Please try again in 1.275s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11722, Requested 420. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11858, Requested 410. Please try again in 1.34s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:37,068 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:37,278 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:37,342 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=3, expected=3, diff=0, confidence=0.46, alignment=0.46, threshold=0.05, mismatch=False
2025-12-10 12:07:37,701 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11739, Requested 403. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11614, Requested 406. Please try again in 100ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11797, Requested 405. Please try again in 1.01s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11670, Requested 406. Please try again in 380ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11855, Requested 402. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11728, Requested 408. Please try again in 680ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11601, Requested 408. Please try again in 45ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11798, Requested 405. Please try again in 1.014999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11671, Requested 403. Please try again in 370ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11851, Requested 404. Please try again in 1.275s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11722, Requested 420. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11858, Requested 410. Please try again in 1.34s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11731, Requested 405. Please try again in 680ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:37,702 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:37,912 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:37,975 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=3, expected=3, diff=0, confidence=0.46, alignment=0.46, threshold=0.05, mismatch=False
2025-12-10 12:07:38,359 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11739, Requested 403. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11614, Requested 406. Please try again in 100ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11797, Requested 405. Please try again in 1.01s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11670, Requested 406. Please try again in 380ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11855, Requested 402. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11728, Requested 408. Please try again in 680ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11601, Requested 408. Please try again in 45ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11798, Requested 405. Please try again in 1.014999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11671, Requested 403. Please try again in 370ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11851, Requested 404. Please try again in 1.275s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11722, Requested 420. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11858, Requested 410. Please try again in 1.34s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11731, Requested 405. Please try again in 680ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 402. Please try again in 30ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:38,361 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:40,020 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:40,090 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=3, diff=1, confidence=0.46, alignment=0.39, threshold=0.05, mismatch=False
2025-12-10 12:07:40,465 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11739, Requested 403. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11614, Requested 406. Please try again in 100ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11797, Requested 405. Please try again in 1.01s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11670, Requested 406. Please try again in 380ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11855, Requested 402. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11728, Requested 408. Please try again in 680ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11601, Requested 408. Please try again in 45ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11798, Requested 405. Please try again in 1.014999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11671, Requested 403. Please try again in 370ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11851, Requested 404. Please try again in 1.275s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11722, Requested 420. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11858, Requested 410. Please try again in 1.34s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11731, Requested 405. Please try again in 680ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 402. Please try again in 30ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:40,466 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:40,670 - SyntheticReviewGen - INFO - Sentiment check: rating=3, attempt=1, base_threshold=0.10, adjusted=0.05
2025-12-10 12:07:40,730 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=3, diff=1, confidence=0.46, alignment=0.39, threshold=0.05, mismatch=False
2025-12-10 12:07:41,099 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11780, Requested 404. Please try again in 919.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11651, Requested 407. Please try again in 290ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11822, Requested 402. Please try again in 1.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11692, Requested 414. Please try again in 530ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11856, Requested 411. Please try again in 1.335s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11730, Requested 411. Please try again in 705ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 407. Please try again in 55ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11739, Requested 403. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11614, Requested 406. Please try again in 100ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11797, Requested 405. Please try again in 1.01s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11670, Requested 406. Please try again in 380ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11855, Requested 402. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11728, Requested 408. Please try again in 680ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11601, Requested 408. Please try again in 45ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11798, Requested 405. Please try again in 1.014999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11671, Requested 403. Please try again in 370ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11851, Requested 404. Please try again in 1.275s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11722, Requested 420. Please try again in 710ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11858, Requested 410. Please try again in 1.34s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11731, Requested 405. Please try again in 680ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11604, Requested 402. Please try again in 30ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11794, Requested 404. Please try again in 990ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:41,101 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:41,313 - SyntheticReviewGen - ERROR - Workflow error for rev_0033: Recursion limit of 100 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.
For troubleshooting, visit: https://docs.langchain.com/oss/python/langgraph/errors/GRAPH_RECURSION_LIMIT
2025-12-10 12:07:41,313 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:41,528 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:07:41,591 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.28, alignment=0.28, threshold=0.10, mismatch=False
2025-12-10 12:07:41,953 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12)
2025-12-10 12:07:41,954 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:43,399 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:07:43,470 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=4, diff=1, confidence=0.76, alignment=0.65, threshold=0.10, mismatch=False
2025-12-10 12:07:43,853 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12)
2025-12-10 12:07:43,856 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:44,072 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:07:44,136 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=4, diff=1, confidence=0.76, alignment=0.65, threshold=0.10, mismatch=False
2025-12-10 12:07:44,502 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:44,504 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:44,711 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:07:44,777 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=4, diff=1, confidence=0.76, alignment=0.65, threshold=0.10, mismatch=False
2025-12-10 12:07:45,146 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:45,147 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:45,353 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:07:45,417 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=4, diff=1, confidence=0.76, alignment=0.65, threshold=0.10, mismatch=False
2025-12-10 12:07:45,786 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:45,787 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:47,461 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:07:47,527 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.56, alignment=0.56, threshold=0.10, mismatch=False
2025-12-10 12:07:47,900 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:47,901 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:48,117 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:07:48,178 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.56, alignment=0.56, threshold=0.10, mismatch=False
2025-12-10 12:07:48,553 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11843, Requested 414. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:48,554 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:48,776 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:07:48,836 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.56, alignment=0.56, threshold=0.10, mismatch=False
2025-12-10 12:07:49,210 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11843, Requested 414. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11711, Requested 418. Please try again in 644.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:49,211 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:50,681 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:07:50,746 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=4, diff=1, confidence=0.56, alignment=0.48, threshold=0.10, mismatch=False
2025-12-10 12:07:51,116 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11843, Requested 414. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11711, Requested 418. Please try again in 644.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:51,117 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:51,323 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:07:51,385 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=4, diff=1, confidence=0.56, alignment=0.48, threshold=0.10, mismatch=False
2025-12-10 12:07:51,756 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11843, Requested 414. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11711, Requested 418. Please try again in 644.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11870, Requested 414. Please try again in 1.42s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:51,757 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:51,964 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:07:52,026 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=4, diff=1, confidence=0.56, alignment=0.48, threshold=0.10, mismatch=False
2025-12-10 12:07:52,396 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11843, Requested 414. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11711, Requested 418. Please try again in 644.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11870, Requested 414. Please try again in 1.42s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11742, Requested 427. Please try again in 845ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:52,397 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:52,607 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:07:52,672 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=4, diff=1, confidence=0.56, alignment=0.48, threshold=0.10, mismatch=False
2025-12-10 12:07:53,049 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11843, Requested 414. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11711, Requested 418. Please try again in 644.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11870, Requested 414. Please try again in 1.42s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11742, Requested 427. Please try again in 845ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11613, Requested 414. Please try again in 134.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:53,050 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:54,280 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:07:54,346 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.78, alignment=0.78, threshold=0.10, mismatch=False
2025-12-10 12:07:54,728 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11843, Requested 414. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11711, Requested 418. Please try again in 644.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11870, Requested 414. Please try again in 1.42s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11742, Requested 427. Please try again in 845ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11613, Requested 414. Please try again in 134.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:54,730 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:54,939 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:07:54,999 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.78, alignment=0.78, threshold=0.10, mismatch=False
2025-12-10 12:07:55,389 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11843, Requested 414. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11711, Requested 418. Please try again in 644.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11870, Requested 414. Please try again in 1.42s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11742, Requested 427. Please try again in 845ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11613, Requested 414. Please try again in 134.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11773, Requested 422. Please try again in 975ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:55,390 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:55,596 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:07:55,658 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.78, alignment=0.78, threshold=0.10, mismatch=False
2025-12-10 12:07:56,026 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11843, Requested 414. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11711, Requested 418. Please try again in 644.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11870, Requested 414. Please try again in 1.42s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11742, Requested 427. Please try again in 845ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11613, Requested 414. Please try again in 134.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11773, Requested 422. Please try again in 975ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11641, Requested 422. Please try again in 315ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:56,027 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:57,212 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:07:57,280 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.71, alignment=0.71, threshold=0.10, mismatch=False
2025-12-10 12:07:57,647 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11843, Requested 414. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11711, Requested 418. Please try again in 644.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11870, Requested 414. Please try again in 1.42s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11742, Requested 427. Please try again in 845ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11613, Requested 414. Please try again in 134.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11773, Requested 422. Please try again in 975ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11641, Requested 422. Please try again in 315ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:57,649 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:57,890 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:07:57,959 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.71, alignment=0.71, threshold=0.10, mismatch=False
2025-12-10 12:07:58,332 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11843, Requested 414. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11711, Requested 418. Please try again in 644.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11870, Requested 414. Please try again in 1.42s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11742, Requested 427. Please try again in 845ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11613, Requested 414. Please try again in 134.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11773, Requested 422. Please try again in 975ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11641, Requested 422. Please try again in 315ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11795, Requested 414. Please try again in 1.044999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:58,333 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:07:58,540 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:07:58,605 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.71, alignment=0.71, threshold=0.10, mismatch=False
2025-12-10 12:07:58,994 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11843, Requested 414. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11711, Requested 418. Please try again in 644.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11870, Requested 414. Please try again in 1.42s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11742, Requested 427. Please try again in 845ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11613, Requested 414. Please try again in 134.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11773, Requested 422. Please try again in 975ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11641, Requested 422. Please try again in 315ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11795, Requested 414. Please try again in 1.044999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11665, Requested 416. Please try again in 405ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:07:58,996 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:08:00,803 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:08:00,863 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.97, alignment=0.97, threshold=0.10, mismatch=False
2025-12-10 12:08:01,239 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11843, Requested 414. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11711, Requested 418. Please try again in 644.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11870, Requested 414. Please try again in 1.42s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11742, Requested 427. Please try again in 845ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11613, Requested 414. Please try again in 134.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11773, Requested 422. Please try again in 975ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11641, Requested 422. Please try again in 315ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11795, Requested 414. Please try again in 1.044999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11665, Requested 416. Please try again in 405ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:08:01,240 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:08:01,444 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:08:01,506 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.97, alignment=0.97, threshold=0.10, mismatch=False
2025-12-10 12:08:01,880 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11843, Requested 414. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11711, Requested 418. Please try again in 644.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11870, Requested 414. Please try again in 1.42s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11742, Requested 427. Please try again in 845ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11613, Requested 414. Please try again in 134.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11773, Requested 422. Please try again in 975ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11641, Requested 422. Please try again in 315ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11795, Requested 414. Please try again in 1.044999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11665, Requested 416. Please try again in 405ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11871, Requested 417. Please try again in 1.44s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:08:01,881 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:08:02,093 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:08:02,153 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.97, alignment=0.97, threshold=0.10, mismatch=False
2025-12-10 12:08:02,529 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11843, Requested 414. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11711, Requested 418. Please try again in 644.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11870, Requested 414. Please try again in 1.42s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11742, Requested 427. Please try again in 845ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11613, Requested 414. Please try again in 134.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11773, Requested 422. Please try again in 975ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11641, Requested 422. Please try again in 315ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11795, Requested 414. Please try again in 1.044999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11665, Requested 416. Please try again in 405ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11871, Requested 417. Please try again in 1.44s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11741, Requested 414. Please try again in 775ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:08:02,531 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:08:02,739 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:08:02,802 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=4, expected=4, diff=0, confidence=0.97, alignment=0.97, threshold=0.10, mismatch=False
2025-12-10 12:08:03,176 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11843, Requested 414. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11711, Requested 418. Please try again in 644.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11870, Requested 414. Please try again in 1.42s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11742, Requested 427. Please try again in 845ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11613, Requested 414. Please try again in 134.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11773, Requested 422. Please try again in 975ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11641, Requested 422. Please try again in 315ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11795, Requested 414. Please try again in 1.044999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11665, Requested 416. Please try again in 405ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11871, Requested 417. Please try again in 1.44s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11741, Requested 414. Please try again in 775ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11612, Requested 429. Please try again in 205ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:08:03,177 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:08:04,333 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:08:04,460 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=4, diff=1, confidence=0.54, alignment=0.46, threshold=0.10, mismatch=False
2025-12-10 12:08:04,836 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11843, Requested 414. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11711, Requested 418. Please try again in 644.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11870, Requested 414. Please try again in 1.42s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11742, Requested 427. Please try again in 845ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11613, Requested 414. Please try again in 134.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11773, Requested 422. Please try again in 975ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11641, Requested 422. Please try again in 315ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11795, Requested 414. Please try again in 1.044999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11665, Requested 416. Please try again in 405ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11871, Requested 417. Please try again in 1.44s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11741, Requested 414. Please try again in 775ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11612, Requested 429. Please try again in 205ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:08:04,837 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:08:05,040 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:08:05,102 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=4, diff=1, confidence=0.54, alignment=0.46, threshold=0.10, mismatch=False
2025-12-10 12:08:05,469 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11843, Requested 414. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11711, Requested 418. Please try again in 644.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11870, Requested 414. Please try again in 1.42s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11742, Requested 427. Please try again in 845ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11613, Requested 414. Please try again in 134.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11773, Requested 422. Please try again in 975ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11641, Requested 422. Please try again in 315ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11795, Requested 414. Please try again in 1.044999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11665, Requested 416. Please try again in 405ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11871, Requested 417. Please try again in 1.44s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11741, Requested 414. Please try again in 775ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11612, Requested 429. Please try again in 205ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11813, Requested 418. Please try again in 1.155s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:08:05,470 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:08:05,679 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:08:05,742 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=4, diff=1, confidence=0.54, alignment=0.46, threshold=0.10, mismatch=False
2025-12-10 12:08:06,108 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11843, Requested 414. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11711, Requested 418. Please try again in 644.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11870, Requested 414. Please try again in 1.42s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11742, Requested 427. Please try again in 845ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11613, Requested 414. Please try again in 134.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11773, Requested 422. Please try again in 975ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11641, Requested 422. Please try again in 315ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11795, Requested 414. Please try again in 1.044999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11665, Requested 416. Please try again in 405ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11871, Requested 417. Please try again in 1.44s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11741, Requested 414. Please try again in 775ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11612, Requested 429. Please try again in 205ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11813, Requested 418. Please try again in 1.155s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11686, Requested 419. Please try again in 525ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:08:06,110 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:08:07,606 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:08:07,670 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=4, diff=1, confidence=0.62, alignment=0.53, threshold=0.10, mismatch=False
2025-12-10 12:08:08,043 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11843, Requested 414. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11711, Requested 418. Please try again in 644.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11870, Requested 414. Please try again in 1.42s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11742, Requested 427. Please try again in 845ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11613, Requested 414. Please try again in 134.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11773, Requested 422. Please try again in 975ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11641, Requested 422. Please try again in 315ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11795, Requested 414. Please try again in 1.044999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11665, Requested 416. Please try again in 405ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11871, Requested 417. Please try again in 1.44s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11741, Requested 414. Please try again in 775ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11612, Requested 429. Please try again in 205ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11813, Requested 418. Please try again in 1.155s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11686, Requested 419. Please try again in 525ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:08:08,044 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:08:08,255 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:08:08,316 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=4, diff=1, confidence=0.62, alignment=0.53, threshold=0.10, mismatch=False
2025-12-10 12:08:08,686 - SyntheticReviewGen - WARNING - Review rev_0033 rejected (attempt 1): Too short: 0 words (min: 40), Low vocabulary: 0 unique words (min: 12), Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11836, Requested 422. Please try again in 1.289999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11707, Requested 418. Please try again in 625ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11579, Requested 425. Please try again in 20ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11843, Requested 414. Please try again in 1.285s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11711, Requested 418. Please try again in 644.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11870, Requested 414. Please try again in 1.42s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11742, Requested 427. Please try again in 845ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11613, Requested 414. Please try again in 134.999999ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11773, Requested 422. Please try again in 975ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11641, Requested 422. Please try again in 315ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11795, Requested 414. Please try again in 1.044999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11665, Requested 416. Please try again in 405ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11871, Requested 417. Please try again in 1.44s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11741, Requested 414. Please try again in 775ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11612, Requested 429. Please try again in 205ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11813, Requested 418. Please try again in 1.155s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11686, Requested 419. Please try again in 525ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing, Generation failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions - Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01k2fzqqz6fwbt1sycpm9b1qw6` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11870, Requested 421. Please try again in 1.455s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing
2025-12-10 12:08:08,688 - SyntheticReviewGen - INFO - Generating review rev_0033 (attempt 1)
2025-12-10 12:08:08,897 - SyntheticReviewGen - INFO - Sentiment check: rating=4, attempt=1, base_threshold=0.20, adjusted=0.10
2025-12-10 12:08:08,962 - SyntheticReviewGen - INFO - Transformer sentiment: predicted=5, expected=4, diff=1, confidence=0.62, alignment=0.53, threshold=0.10, mismatch=False
